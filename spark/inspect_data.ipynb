{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql.functions  as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = \"/home/de-zoom/agile-polymer-376104-a02a7ed99393.json\"\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[*]\")\n",
    "    .setAppName(\"test\")\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-latest.jar\")\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/06 15:14:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "datasets_df = spark.read.parquet(\"gs://pwc-de-datalake/data/processed_data/datasets.parquet\")\n",
    "links_papers_code_df = spark.read.parquet(\n",
    "    \"gs://pwc-de-datalake/data/processed_data/links_between_papers_and_code.parquet\"\n",
    ")\n",
    "papers_df = spark.read.parquet(\n",
    "    \"gs://pwc-de-datalake/data/processed_data/papers_with_abstracts.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(papers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- introduced_date: timestamp (nullable = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- variants: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- num_papers: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = datasets_df.withColumn(\"num_papers\", datasets_df[\"num_papers\"].cast(types.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+--------------------+------------------+--------------------+----------+\n",
      "|                 url|         name|           full_name|         description|    introduced_date|               tasks|         languages|            variants|num_papers|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+--------------------+------------------+--------------------+----------+\n",
      "|https://paperswit...|        MNIST|                    |The **MNIST** dat...|1998-11-01 00:00:00|[Density Estimati...|         [English]|[Mnist-Full, Rota...|      6014|\n",
      "|https://paperswit...|       CelebA|CelebFaces Attrib...|CelebFaces Attrib...|2015-01-01 00:00:00|[Multi-Task Learn...|                []|[Celeba 256X256, ...|      2475|\n",
      "|https://paperswit...|     JFT-300M|            JFT-300M|**JFT-300M** is a...|2017-07-10 00:00:00|[Image Classifica...|                []|          [Jft-300M]|        97|\n",
      "|https://paperswit...|         GLUE|General Language ...|General Language ...|2019-01-01 00:00:00|[Qnli, Semantic T...|         [English]|[Qnli, Glue Mnli,...|      1991|\n",
      "|https://paperswit...|     MultiNLI|Multi-Genre Natur...|The **Multi-Genre...|2018-01-01 00:00:00|[Text Generation,...|         [English]|[Multinli Dev, Mu...|      1286|\n",
      "|https://paperswit...|     ImageNet|                    |The **ImageNet** ...|2009-01-01 00:00:00|[Density Estimati...|[Chinese, English]|[Nas-Bench-201, I...|     10448|\n",
      "|https://paperswit...|Penn Treebank|                    |The English **Pen...|1993-01-01 00:00:00|[Constituency Gra...|                []|[Penn Treebank (C...|      1284|\n",
      "|https://paperswit...| WikiText-103|        WikiText-103|The WikiText lang...|2016-09-26 00:00:00|[Text Generation,...|         [English]|      [Wikitext-103]|       359|\n",
      "|https://paperswit...|          LFW|Labeled Faces in ...|The **LFW** datas...|               null|[Blind Face Resto...|                []|[Labeled Faces In...|       705|\n",
      "|https://paperswit...|      WikiSQL|             WikiSQL|**WikiSQL** consi...|2017-01-01 00:00:00|[Sql Chatbots, Co...|                []|           [Wikisql]|       171|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+--------------------+------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "datasets_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_url: string (nullable = true)\n",
      " |-- paper_title: string (nullable = true)\n",
      " |-- paper_arxiv_id: string (nullable = true)\n",
      " |-- is_official: boolean (nullable = true)\n",
      " |-- mentioned_in_paper: boolean (nullable = true)\n",
      " |-- mentioned_in_github: boolean (nullable = true)\n",
      " |-- framework: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links_papers_code_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+-----------+------------------+-------------------+---------+\n",
      "|           paper_url|         paper_title|  paper_arxiv_id|is_official|mentioned_in_paper|mentioned_in_github|framework|\n",
      "+--------------------+--------------------+----------------+-----------+------------------+-------------------+---------+\n",
      "|https://paperswit...|Automatic Post-Ed...|            null|      false|             false|              false|       tf|\n",
      "|https://paperswit...|Plug and Play Lan...|      1912.02164|      false|             false|              false|  pytorch|\n",
      "|https://paperswit...|AttnGAN: Fine-Gra...|      1711.10485|      false|             false|              false|  pytorch|\n",
      "|https://paperswit...|The Measurement C...|quant-ph/0412135|      false|             false|               true|     none|\n",
      "|https://paperswit...|mudirac: a Dirac ...|      2004.11876|       true|              true|               true|     none|\n",
      "|https://paperswit...|Achieving Human P...|      1803.05567|       true|              true|              false|     none|\n",
      "|https://paperswit...|Light Gated Recur...|      1803.10225|       true|              true|              false|  pytorch|\n",
      "|https://paperswit...|MNIST Dataset Cla...|      1809.06846|       true|              true|               true|     none|\n",
      "|https://paperswit...|Maximum Classifie...|      1712.02560|      false|             false|              false|  pytorch|\n",
      "|https://paperswit...|Bottom-Up and Top...|      1707.07998|      false|             false|               true|  pytorch|\n",
      "+--------------------+--------------------+----------------+-----------+------------------+-------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links_papers_code_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_url: string (nullable = true)\n",
      " |-- arxiv_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- proceeding: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+---------------+--------------------+--------------------+-------------------+\n",
      "|           paper_url|  arxiv_id|               title|            abstract|     proceeding|             authors|               tasks|               date|\n",
      "+--------------------+----------+--------------------+--------------------+---------------+--------------------+--------------------+-------------------+\n",
      "|https://paperswit...|1805.10616|Dynamic Network M...|Can evolving netw...|NeurIPS 2018 12|[Elahe Ghalebi, J...|                  []|2018-05-27 00:00:00|\n",
      "|https://paperswit...|1806.06827|PAC-Bayes bounds ...|PAC-Bayes bounds ...|NeurIPS 2018 12|[Csaba Szepesvari...|                  []|2018-06-18 00:00:00|\n",
      "|https://paperswit...|1806.06820|Automated Bridge ...|This paper invest...|           null|[Tu A. Hoang, Bil...|[Big-Bench Machin...|2018-06-18 00:00:00|\n",
      "|https://paperswit...|1802.06093|Gradient descent ...|We analyze algori...|      ICML 2018|[Peter L. Bartlet...|                  []|2018-02-16 00:00:00|\n",
      "|https://paperswit...|1806.06811|Temporal coherenc...|In order to provi...|           null|[Stefanie Speidel...|[Self-Supervised ...|2018-06-18 00:00:00|\n",
      "|https://paperswit...|1801.04487|Better Runtime Gu...|Apart from few ex...|           null|    [Benjamin Doerr]|                  []|2018-01-13 00:00:00|\n",
      "|https://paperswit...|1806.00187|Scaling Neural Ma...|Sequence to seque...|     WS 2018 10|[Michael Auli, Da...|[Translation, Que...|2018-06-01 00:00:00|\n",
      "|https://paperswit...|1806.06802|Interpretable Alm...|We aim to create ...|           null|[Aw Dieng, Yameng...|  [Causal Inference]|2018-06-18 00:00:00|\n",
      "|https://paperswit...|1806.06793|Deep Spatiotempor...|Automatic pain in...|           null|[Abdenour Hadid, ...|                  []|2018-06-18 00:00:00|\n",
      "|https://paperswit...|1806.06784|Robust inference ...|Many estimators o...|           null|[Mark J. Van Der ...|        [Regression]|2018-06-18 00:00:00|\n",
      "+--------------------+----------+--------------------+--------------------+---------------+--------------------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "papers_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_framework_df = (\n",
    "    papers_df.join(\n",
    "        links_papers_code_df,\n",
    "        papers_df[\"paper_url\"] == links_papers_code_df[\"paper_url\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .filter((F.col(\"framework\").isNotNull()) & (F.col(\"framework\") != \"none\"))\n",
    "    .select(\"title\", \"date\", \"framework\", \"is_official\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- introduced_date: timestamp (nullable = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- variants: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- num_papers: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_datasets_df = datasets_df.select(\n",
    "    \"name\", \"introduced_date\", F.explode(\"languages\").alias(\"language\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_url: string (nullable = true)\n",
      " |-- arxiv_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- proceeding: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_proceeding_name(proceeding_name: str):\n",
    "    if not proceeding_name:\n",
    "        return proceeding_name\n",
    "    i = len(proceeding_name)\n",
    "    while i > 0 and not proceeding_name[i-1].isalpha():\n",
    "        i -= 1\n",
    "    return proceeding_name[:i]\n",
    "\n",
    "proceeding_udf = F.udf(clean_proceeding_name, returnType=types.StringType())\n",
    "\n",
    "proceedings_papers_df = papers_df \\\n",
    "    .withColumn(\"proceeding\", proceeding_udf(papers_df.proceeding)) \\\n",
    "    .filter(F.col(\"proceeding\").isNotNull()) \\\n",
    "    .select(\"title\", \"proceeding\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_url: string (nullable = true)\n",
      " |-- arxiv_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- proceeding: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- full_name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- introduced_date: timestamp (nullable = true)\n",
      " |-- tasks: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- variants: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- num_papers: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_df.printSchema()\n",
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_task_df = papers_df.filter(papers_df.tasks.isNotNull()).select(\n",
    "    \"date\", F.explode(\"tasks\").alias(\"task\")\n",
    ")\n",
    "datasets_task_df = datasets_df.filter(datasets_df.tasks.isNotNull()).select(\n",
    "    \"name\", \"introduced_date\", F.explode(\"tasks\").alias(\"task\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_framework_df\n",
    "languages_datasets_df\n",
    "proceedings_papers_df\n",
    "papers_task_df\n",
    "datasets_task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+-----------+\n",
      "|               title|               date|framework|is_official|\n",
      "+--------------------+-------------------+---------+-----------+\n",
      "|Temporal coherenc...|2018-06-18 00:00:00|  pytorch|       true|\n",
      "|Scaling Neural Ma...|2018-06-01 00:00:00|  pytorch|      false|\n",
      "|Scaling Neural Ma...|2018-06-01 00:00:00|  pytorch|      false|\n",
      "|Scaling Neural Ma...|2018-06-01 00:00:00|  pytorch|      false|\n",
      "|Scaling Neural Ma...|2018-06-01 00:00:00|  pytorch|      false|\n",
      "|Scaling Neural Ma...|2018-06-01 00:00:00|  pytorch|       true|\n",
      "|Consistent Indivi...|2018-02-12 00:00:00|       tf|      false|\n",
      "|Consistent Indivi...|2018-02-12 00:00:00|       tf|      false|\n",
      "|Consistent Indivi...|2018-02-12 00:00:00|       tf|      false|\n",
      "|Closing the Gener...|2018-06-18 00:00:00|  pytorch|       true|\n",
      "+--------------------+-------------------+---------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_framework_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------+\n",
      "|        name|    introduced_date|   language|\n",
      "+------------+-------------------+-----------+\n",
      "|       MNIST|1998-11-01 00:00:00|    English|\n",
      "|        GLUE|2019-01-01 00:00:00|    English|\n",
      "|    MultiNLI|2018-01-01 00:00:00|    English|\n",
      "|    ImageNet|2009-01-01 00:00:00|    Chinese|\n",
      "|    ImageNet|2009-01-01 00:00:00|    English|\n",
      "|WikiText-103|2016-09-26 00:00:00|    English|\n",
      "|  OpenAI Gym|2016-01-01 00:00:00|Azerbaijani|\n",
      "|  WikiText-2|2016-09-26 00:00:00|    English|\n",
      "|   WikiLarge|2017-01-01 00:00:00|    English|\n",
      "|   Flickr30k|2014-01-01 00:00:00|    English|\n",
      "+------------+-------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages_datasets_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+\n",
      "|               title|proceeding|               date|\n",
      "+--------------------+----------+-------------------+\n",
      "|Dynamic Network M...|   NeurIPS|2018-05-27 00:00:00|\n",
      "|PAC-Bayes bounds ...|   NeurIPS|2018-06-18 00:00:00|\n",
      "|Gradient descent ...|      ICML|2018-02-16 00:00:00|\n",
      "|Scaling Neural Ma...|        WS|2018-06-01 00:00:00|\n",
      "|BinGAN: Learning ...|   NeurIPS|2018-06-18 00:00:00|\n",
      "|A Memory Network ...|      CVPR|2018-05-08 00:00:00|\n",
      "|    Surface Networks|      CVPR|2017-05-30 00:00:00|\n",
      "|Extracting Automa...|      ICML|2017-11-27 00:00:00|\n",
      "|Tree Edit Distanc...|      ICML|2018-06-13 00:00:00|\n",
      "|Banach Wasserstei...|   NeurIPS|2018-06-18 00:00:00|\n",
      "+--------------------+----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "proceedings_papers_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|               date|                task|\n",
      "+-------------------+--------------------+\n",
      "|2018-06-18 00:00:00|Big-Bench Machine...|\n",
      "|2018-06-18 00:00:00|Self-Supervised L...|\n",
      "|2018-06-01 00:00:00|         Translation|\n",
      "|2018-06-01 00:00:00|  Question Answering|\n",
      "|2018-06-01 00:00:00| Machine Translation|\n",
      "|2018-06-18 00:00:00|    Causal Inference|\n",
      "|2018-06-18 00:00:00|          Regression|\n",
      "|2018-02-12 00:00:00|Big-Bench Machine...|\n",
      "|2018-06-18 00:00:00|Dimensionality Re...|\n",
      "|2018-06-18 00:00:00|           Retrieval|\n",
      "+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers_task_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+\n",
      "| name|    introduced_date|                task|\n",
      "+-----+-------------------+--------------------+\n",
      "|MNIST|1998-11-01 00:00:00|  Density Estimation|\n",
      "|MNIST|1998-11-01 00:00:00|Structured Predic...|\n",
      "|MNIST|1998-11-01 00:00:00|Clustering Algori...|\n",
      "|MNIST|1998-11-01 00:00:00|General Classific...|\n",
      "|MNIST|1998-11-01 00:00:00|                 Nmt|\n",
      "|MNIST|1998-11-01 00:00:00|Personalized Fede...|\n",
      "|MNIST|1998-11-01 00:00:00|Sequential Image ...|\n",
      "|MNIST|1998-11-01 00:00:00|Automatic Speech ...|\n",
      "|MNIST|1998-11-01 00:00:00|Unsupervised Imag...|\n",
      "|MNIST|1998-11-01 00:00:00|                 Sts|\n",
      "+-----+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_task_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
