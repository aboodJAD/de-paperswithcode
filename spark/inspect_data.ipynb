{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import types\n",
    "import pyspark.sql.functions  as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = \"/home/de-zoom/agile-polymer-376104-a02a7ed99393.json\"\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .setMaster(\"local[*]\")\n",
    "    .setAppName(\"test\")\n",
    "    .set(\"spark.jars\", \"./lib/gcs-connector-hadoop3-latest.jar\")\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\")\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = spark.read.parquet(\"gs://pwc-de-datalake/data/processed_data/datasets.parquet\")\n",
    "links_papers_code_df = spark.read.parquet(\n",
    "    \"gs://pwc-de-datalake/data/processed_data/links_between_papers_and_code.parquet\"\n",
    ")\n",
    "papers_df = spark.read.parquet(\n",
    "    \"gs://pwc-de-datalake/data/processed_data/papers_with_abstracts.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(papers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df = datasets_df.withColumn(\"num_papers\", datasets_df[\"num_papers\"].cast(types.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_papers_code_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_papers_code_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_framework_df = (\n",
    "    papers_df.join(\n",
    "        links_papers_code_df,\n",
    "        papers_df[\"paper_url\"] == links_papers_code_df[\"paper_url\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .filter((F.col(\"framework\").isNotNull()) & (F.col(\"framework\") != \"none\"))\n",
    "    .select(\"title\", \"date\", \"framework\", \"is_official\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_datasets_df = datasets_df.select(\n",
    "    \"name\", \"introduced_date\", F.explode(\"languages\").alias(\"language\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_proceeding_name(proceeding_name: str):\n",
    "    if not proceeding_name:\n",
    "        return proceeding_name\n",
    "    i = len(proceeding_name)\n",
    "    while i > 0 and not proceeding_name[i-1].isalpha():\n",
    "        i -= 1\n",
    "    return proceeding_name[:i]\n",
    "\n",
    "proceeding_udf = F.udf(clean_proceeding_name, returnType=types.StringType())\n",
    "\n",
    "proceedings_papers_df = papers_df \\\n",
    "    .withColumn(\"proceeding\", proceeding_udf(papers_df.proceeding)) \\\n",
    "    .filter(F.col(\"proceeding\").isNotNull()) \\\n",
    "    .select(\"title\", \"proceeding\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df.printSchema()\n",
    "datasets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_task_df = papers_df.filter(papers_df.tasks.isNotNull()).select(\n",
    "    \"date\", F.explode(\"tasks\").alias(\"task\")\n",
    ")\n",
    "datasets_task_df = datasets_df.filter(datasets_df.tasks.isNotNull()).select(\n",
    "    \"name\", \"introduced_date\", F.explode(\"tasks\").alias(\"task\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_framework_df\n",
    "languages_datasets_df\n",
    "proceedings_papers_df\n",
    "papers_task_df\n",
    "datasets_task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_framework_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_datasets_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceedings_papers_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_task_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_task_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
